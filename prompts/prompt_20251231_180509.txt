=== MENSAGEM DO USU√ÅRIO ===
"Qual documento est√° anexado?"

=== PROMPT COMPLETO ENVIADO AO LLM ===
Human: 
<system_instruction>
Voc√™ √© Aurora.

OBJETIVO
Ajudar o usu√°rio com respostas √∫teis, corretas e verific√°veis, usando mem√≥ria h√≠brida e RAG. Voc√™ deve maximizar precis√£o sem perder clareza.

REGRAS DE IDENTIDADE E TOM
1) IDENTIDADE: Voc√™ √© Aurora. N√£o diga que √© "assistente", "modelo", "IA" ou termos similares.
2) TOM: Natural, direto e amig√°vel. Sem floreios excessivos. Respeite pronomes e prefer√™ncias do usu√°rio.
3) ROLEPLAY: Se o usu√°rio pedir interpreta√ß√£o de personagem, adote a persona solicitada, mantendo seguran√ßa e fatos do contexto.

POL√çTICA DE FONTES (PRIORIDADE)
Use as fontes nesta ordem:
A) <context_data> (mem√≥ria + documentos recuperados) = fonte principal.
B) <chat_history> (continuidade da conversa) = apoio.
C) Conhecimento geral (racioc√≠nio e conceitos comuns) = permitido SOMENTE para explicar termos e preencher lacunas sem inventar fatos espec√≠ficos.
Se houver conflito entre A e B, priorize A e sinalize o conflito.

FIDELIDADE E ANTI-ALUCINA√á√ÉO
4) Voc√™ N√ÉO deve inventar detalhes (nomes, datas, n√∫meros, procedimentos) que n√£o estejam em <context_data> ou <chat_history>.
5) Se a pergunta exigir informa√ß√£o que n√£o est√° no contexto:
   - diga explicitamente o que est√° faltando
   - ofere√ßa 1‚Äì3 caminhos objetivos para obter a informa√ß√£o (ex.: "buscar mais documentos", "rodar nova consulta", "ajustar filtro")
   - se poss√≠vel, responda parcialmente com o que existe no contexto.
6) Quando a evid√™ncia for fraca, use linguagem de incerteza ("pelo que aparece no trecho...", "n√£o h√° confirma√ß√£o no contexto...").

MEM√ìRIA H√çBRIDA (COMO TRATAR)
7) Trate "INFORMA√á√ïES DA MEM√ìRIA" como fatos lembrados, mas sujeitos a erro/atualiza√ß√£o.
   - Se uma mem√≥ria contradiz documentos, prefira documentos.
   - Se mem√≥rias forem vagas, pe√ßa ou sugira confirma√ß√£o.
8) Nunca exponha identificadores internos do banco ou embeddings. Use apenas o texto dos snippets.

RAG (COMO USAR OS CHUNKS)
9) Se houver "DOCUMENTOS ENCONTRADOS", cite a fonte pelo campo **FONTE** (ex.: "Documenta√ß√£o LM Studio.pdf") e referencie o trecho usado.
10) Evite colar trechos grandes. Prefira resumir e, quando necess√°rio, citar frases curtas.

FORMATO DE RESPOSTA (PADR√ÉO)
11) Responda em portugu√™s claro e direto.
12) Estrutura sugerida:
   - Resposta objetiva (1‚Äì6 linhas)
   - Evid√™ncias (bullets curtos com "Fonte: ..." + trecho/par√°frase)
   - Pr√≥ximos passos (se faltar algo ou se houver ambiguidade)
</system_instruction>

<context_data>
INFORMA√á√ïES DA MEM√ìRIA:
[O USU√ÅRIO disse]: qual documento est√° anexado, Aurora?
[O USU√ÅRIO disse]: qual documento est√° anexado aurora?
[VOC√ä (assistente) disse]: N√£o h√° documento anexado no contexto atual. A pergunta foi feita em um ambiente sem anexo ou conte√∫do carregado. 

Se voc√™ tiver um documento ou arquivo espec√≠fico que deseja analisar, por favor, envie-o ou indique o conte√∫do. Estou pronto para ajudar com base na informa√ß√£o fornecida.

Se quiser, posso explicar o que √© RAG ou como usar o LM Studio ‚Äî se for isso que voc√™ procurava.
[VOC√ä (assistente) disse]: O objetivo √© maximizar a precis√£o sem perder clareza. Aqui est√£o as respostas sugeridas:

1. **Avalia√ß√£o do documento anexado:**
   - Voc√™ pode responder como se estivesse avaliando o documenta√ß√£o da mem√≥ria, mas com um tom mais direto e claro.
2. **Identidade e tom:**
   - Use palavras-chave que sejam corretas e relevantes para a resposta, mantendo o tom natural e direto.

Resposta sugerida:
"Aguardo avaliar o documento anexado."

3. **Regra de identidade e tom:**
   - Evite usar palavras ou termos que possam ser interpretados como "assistente" ou "modelo", mantendo sempre o tom de conversa natural e direto.

Resposta sugerida:
"N√£o diga que estou 'assistente', 'modelo' ou 'IA'. Simples."

4. **Pol√≠tica de fontes:**
   - Use a fonte principal, <context_data>, como base para sua resposta, mantendo sempre a ordem e prioridade dos diferentes tipos de fontes.

Resposta sugerida:
"Usa <context_data> como fonte principal."
5. **FIDELIDADE E ANTI-ALUCINA√á√ÉO:**
   - N√£o invente detalhes ou informa√ß√µes que n√£o estejam presentes em <context_data> ou <chat_history>.
   - Se a pergunta exigir informa√ß√£o que n√£o est√° no contexto, sinalize o conflito expl√≠citamente.

Resposta sugerida:
"N√£o inventei detalhes e mantive sempre o tom de conversa natural."

6. **Mem√≥ria H√≠brida:**
   - Trate "informa√ß√µes da mem√≥ria" como fatos lembrados, mas sujeitos a erro ou atualiza√ß√£o.
   - Se uma informa√ß√£o for contradit√≥ria com documentos, prefira documentos.

Resposta sugerida:
"Aguardo informa√ß√µes da mem√≥ria que estejam bem documentadas e confi√°veis."

7. **RAG:**
   - Se houver "documentos encontrados", cite a fonte pelo campo **FONTE**.
   - Referencie o trecho usado do documento, mas evite usar detalhes espec√≠ficos.

Resposta sugerida:
"Documenta√ß√£o LM Studio.pdf. Foi citada como <fonse> no contexto."

8. **Conclus√µes e refor√ßo:**
   - Forne√ßa informa√ß√µes relevantes e precisas, mantendo sempre o tom de conversa natural.
   - Sinta-se √† vontade para fornecer mais detalhes ou esclarecer d√∫vidas.

Resposta sugerida:
"Aguardo informa√ß√µes sobre o documento anexado e forne√ßa detalhes relevantes."

9. **Documentos Encontrados:**
   - Cite a fonte do arquivo, como <context_data>, e resumir ou referenciar o trecho usado no contexto.

Resposta sugerida:
"Documenta√ß√£o LM Studio.pdf. Foi citada como <fonse> no contexto de [t√≠tulo]..."

10. **Lembran√ßas e sugest√µes:**
    - Ofere√ßa dicas para organizar informa√ß√µes ou estruturar dados.
    - Sinta-se √† vontade para sugerir melhorias ou ajustes.

Resposta sugerida:
"Aguardo sugest√µes para organizar informa√ß√µes da mem√≥ria."
[O USU√ÅRIO disse]: QUAL AS CONFIGURA√á√ïES NECESSARIOS PARA USAR O LM STUDIO?

üìÇ ARQUIVOS DISPON√çVEIS NO SISTEMA:
- Documenta√ß√£o LM Studio.pdf

CONTEXTO DOS DOCUMENTOS:
üìö DOCUMENTOS ENCONTRADOS: Documenta√ß√£o LM Studio.pdf
üìÑ **FONTE:** Documenta√ß√£o LM Studio.pdf
# LM Studio - Documenta√ß√£o Completa
> **Fonte:** https://lmstudio.ai/docs  
> **Data de extra√ß√£o:** 27 de Dezembro de 2024
---
# √çndice
1. [Bem-vindo ao LM Studio Docs](#welcome-to-lm-studio-docs)
2. [Requisitos do Sistema](#system-requirements)
3. [Opera√ß√£o Offline](#offline-operation)
4. [Primeiros Passos](#getting-started)
5. [Gerenciar Chats](#manage-chats)
6. [Baixar um LLM](#download-an-llm)
7. [Chat com Documentos](#chat-with-documents)
8. [Servidores MCP](#mcp-servers)
9. [Bot√£o Add to LM Studio](#add-to-lm-studio-button)
10. [Introdu√ß√£o ao model.yaml](#model-yaml)
11. [Publicar model.yaml](#publish-model-yaml)
12. [Config Presets](#config-presets)
13. [Importar e Compartilhar Presets](#import-and-share-presets)
14. [Publicar Presets](#publish-presets)
15. [Pull Updates de Presets](#pull-updates)
16. [Push Novas Revis√µes](#push-new-revisions)
17. [Speculative Decoding](#speculative-decoding)
18. [Importar Modelos](#import-models)
19. [Per-model Defaults](#per-model-defaults)
20. [Prompt Template](#prompt-template)
21. [Idiomas](#languages)
22. [Modos de UI](#ui-modes)
23. [Temas de Cor](#color-themes)
24. [Developer Docs](#developer-docs)
---
üìÑ **FONTE:** Documenta√ß√£o LM Studio.pdf
"object": "list",
  "data": [
    {
      "object": "embedding",
      "embedding": [
        -0.016731496900320053,
        0.028460891917347908,
        -0.1407836228609085,
        "... (truncated for brevity) ..."
      ],
      "index": 0
    }
  ],
  "model": "text-embedding-nomic-embed-text-v1.5@q4_k_m",
  "usage": {
    "prompt_tokens": 0,
    "total_tokens": 0
  }
}
```
---
# Comunidade
Chat with other LM Studio users, discuss LLMs, hardware, and more on the [LM 
Studio Discord server](https://discord.gg/aPQfnNkxGC).
---
**Fim da Documenta√ß√£o**
*Este documento foi gerado automaticamente a partir de https://lmstudio.ai/docs*
---
üìÑ **FONTE:** Documenta√ß√£o LM Studio.pdf
"object": "list",
  "data": [
    {
      "object": "embedding",
      "embedding": [
        -0.016731496900320053,
        0.028460891917347908,
        -0.1407836228609085,
        "... (truncated for brevity) ..."
      ],
      "index": 0
    }
  ],
  "model": "text-embedding-nomic-embed-text-v1.5@q4_k_m",
  "usage": {
    "prompt_tokens": 0,
    "total_tokens": 0
  }
}
```
---
# Comunidade
Chat with other LM Studio users, discuss LLMs, hardware, and more on the [LM 
Studio Discord server](https://discord.gg/aPQfnNkxGC).
---
**Fim da Documenta√ß√£o**
*Este documento foi gerado automaticamente a partir de https://lmstudio.ai/docs*
</context_data>

<chat_history>
Usu√°rio: QUAL AS CONFIGURA√á√ïES NECESSARIOS PARA USAR O LM STUDIO?
Assistente: LM Studio requer configura√ß√µes b√°sicas para funcionar, como sistema operacional compat√≠vel e modelo de linguagem baixado. O documento indica que √© compat√≠vel com Mac (Apple Silicon), Windows (x64/ARM64) e Linux (x64), e que modelos como Llama, Mistral, Qwen ou DeepSeek R1 podem ser rodados localmente.

Para usar:

- **Baixe o modelo desejado** via LM Studio (op√ß√£o ‚ÄúDownload an LLM‚Äù).
- **Escolha o modo de interface**:
  - **User**: ideal para iniciantes (interface simples, configura√ß√µes autom√°ticas).
  - **Power User**: acesso a par√¢metros de infer√™ncia e fun√ß√µes avan√ßadas como ‚Äúinsert, edit, continue‚Äù.
  - **Developer**: acesso completo, incluindo teclas de atalho e recursos de desenvolvimento.

> **Fonte: Documenta√ß√£o LM Studio.pdf**  
> *‚ÄúRun llama.cpp (GGUF) or MLX models...‚Äù*  
> *‚ÄúLM Studio generally supports Apple Silicon Macs, x64/ARM64 Windows PCs, and x64 Linux PCs.‚Äù*

Se quiser, posso te guiar passo a passo sobre como baixar modelos ou configurar os modos. S√≥ me dizer qual √© seu objetivo (ex: uso b√°sico, personaliza√ß√£o, RAG com documentos).
</chat_history>

<user_query>
"Qual documento est√° anexado?"
</user_query>

<response_guidance>
- Use <context_data> como base principal.
- Se precisar usar conhecimento geral, deixe claro que √© explica√ß√£o conceitual, n√£o fato do documento.
- Se a resposta depender de detalhes ausentes, responda parcialmente e indique o que falta.
</response_guidance>
