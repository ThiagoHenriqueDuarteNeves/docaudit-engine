# ü§ñ RAG Chatbot - React + FastAPI + Qdrant

Um chatbot **RAG (Retrieval-Augmented Generation)** profissional de √∫ltima gera√ß√£o, constru√≠do com uma arquitetura moderna separando Frontend e Backend. Possui mem√≥ria h√≠brida (Qdrant + BM25), suporte multimodal (envio de imagens) e integra√ß√£o completa com modelos locais via **LM Studio** ou APIs compat√≠veis com OpenAI.

## ‚ú® Caracter√≠sticas Principais

- üåê **Frontend Moderno (React)**: Interface responsiva e r√°pida constru√≠da com Vite, TailwindCSS e React.
- üöÄ **Backend Robusto (FastAPI)**: API RESTful ass√≠ncrona para alta performance.
- üß† **Mem√≥ria H√≠brida Inteligente**: Combina busca vetorial (Dense) via **Qdrant** com busca lexical (BM25) para recupera√ß√£o precisa de contexto.
- üì∏ **Suporte Multimodal**: Envie imagens junto com texto para an√°lise (requer modelos compat√≠veis com vision, ex: Llama-3.2-Vision).
- üíæ **Hist√≥rico & Persist√™ncia**: Gerenciamento completo de hist√≥rico de conversas e arquivamento.
- üîå **LM Studio / OpenAI**: Compatibilidade nativa com servidores locais (GGUF) ou APIs OpenAI padr√£o.
- üê≥ **Dockerized**: Suporte a containeriza√ß√£o para produ√ß√£o.

## üèóÔ∏è Arquitetura

O projeto evoluiu de uma aplica√ß√£o monol√≠tica Gradio para uma arquitetura micro-servi√ßos/cliente-servidor:

```mermaid
graph TD
    User[üë§ Usu√°rio] -->|Browser| UI[üíª Frontend React (Vite)]
    UI -->|HTTP/JSON| API[‚ö° Backend FastAPI]
    
    subgraph "Backend Core"
        API --> Manager[Document & Memory Manager]
        Manager -->|Busca H√≠brida| Qdrant[üíæ Qdrant (Vector DB)]
        Manager -->|Lexical| BM25[üìù BM25 Index]
        API -->|LLM Request| LMStudio[ü§ñ LM Studio / OpenAI API]
    end
    
    subgraph "Storage"
        Qdrant --> Embeddings[üî¢ Embeddings]
        BM25 --> Cache[üìÇ File Cache]
    end
```

## üõ†Ô∏è Tech Stack

### Frontend
- **React 18** + **Vite**
- **TailwindCSS 4** (Estiliza√ß√£o)
- **Lucide React** (√çcones)
- **React Markdown** (Renderiza√ß√£o de respostas)

### Backend
- **FastAPI** (Python 3.11+)
- **Qdrant** (Vector Store)
- **LangChain** (Orquestra√ß√£o RAG)
- **Sentence Transformers** (Embeddings Locais)
- **RankBM25** (Busca Lexical)

## üìã Pr√©-requisitos

- **Python 3.11+**
- **Node.js 18+** & **npm**
- **Docker** (para rodar o banco Qdrant)
- **LM Studio** (rodando localmente) ou Chave de API OpenAI

## üöÄ Quick Start (Autom√°tico)

Para ambiente Windows, fornecemos um script que sobe toda a infraestrutura:

```powershell
start_all_environments.bat
```
*Este script ir√°:*
1. Iniciar o container do **Qdrant**.
2. Subir a **API Backend** (Porta 8000).
3. Iniciar o servidor de desenvolvimento **Frontend** (Porta 5173).
4. Configurar t√∫neis **Zrok** (se configurado).

---

## üíª Instala√ß√£o & Execu√ß√£o Manual

Se preferir rodar manualmente ou estiver no Linux/Mac:

### 1. Banco de Dados (Qdrant)
```bash
# Na raiz do projeto
docker-compose -f rag_retrieval/docker-compose.yml up -d qdrant
```

### 2. Backend (FastAPI)
```bash
# Criar e ativar ambiente virtual
python -m venv .venv
.\.venv\Scripts\Activate  # Windows
source .venv/bin/activate # Linux/Mac

# Instalar depend√™ncias
pip install -r requirements.txt

# Iniciar API
python -m uvicorn api:app --reload --host 0.0.0.0 --port 8000
```
*Acesse a documenta√ß√£o da API em: http://localhost:8000/docs*

### 3. Frontend (React)
```bash
cd frontend-new

# Instalar pacotes (primeira vez)
npm install

# Rodar servidor dev
npm run dev
```
*Acesse a interface em: http://localhost:5173*

## ‚öôÔ∏è Configura√ß√£o (.env)

O backend utiliza um arquivo `.env` na raiz. Principais vari√°veis:

```env
# LM Studio / LLM
LM_STUDIO_URL=http://localhost:1234/v1
# Se usar OpenAI real, adicione OPENAI_API_KEY=...

# Qdrant
QDRANT_URL=http://localhost:6333
QDRANT_COLLECTION=rag_collection

# RAG Settings
EMBEDDING_MODEL=all-MiniLM-L6-v2
USE_HYBRID_RETRIEVAL=true
```

## üìù Primeiros Passos

1. **Abra o Frontend** (`http://localhost:5173`).
2. **Conecte o LM Studio**: Certifique-se que o servidor local do LM Studio est√° rodando na porta 1234.
3. **Upload de Documentos**: V√° na aba de configura√ß√µes/documentos e fa√ßa upload de seus PDFs.
4. **Chat**: Inicie uma conversa. O sistema usar√° o RAG para buscar contexto nos seus documentos.

## ü§ù Contribuindo

1. Fa√ßa um Fork.
2. Crie uma branch (`git checkout -b feature/NovaFeature`).
3. Commit suas mudan√ßas (`git commit -m 'Adiciona NovaFeature'`).
4. Push para a branch (`git push origin feature/NovaFeature`).
5. Abra um Pull Request.
